Summary:
The paper introduces a novel end-to-end latent dialogue act model (DiactTOD) to improve the quality of response generation in task-oriented dialogue systems. The model represents dialogue acts in a latent space, which allows for generalization across different datasets and tasks. The model is pre-trained on a large corpus of dialogues and can generate controllable responses using these latent representations. Experimental results on the MultiWOZ dataset demonstrate that DiactTOD outperforms previous state-of-the-art methods in zero-shot, few-shot, and full data fine-tuning settings.

Bullet Points:
1. DiactTOD is an end-to-end latent dialogue act model for task-oriented dialogue systems.
2. The model learns generalized latent dialogue acts that can be applied across different datasets and tasks.
3. Pre-training on a large corpus allows the model to generate controllable responses using latent representations.
4. DiactTOD achieves state-of-the-art performance on the MultiWOZ dataset in zero-shot, few-shot, and full data fine-tuning settings.
5. The model provides more relevant and complete information to satisfy users' information needs.
6. Dialogue act control improves the model's performance in low-resource settings.
7. Zero-shot dialogue act prediction is effective without any downstream fine-tuning.
8. The model's performance depends on the pre-training configuration and the use of dialogue act control.
9. The model's performance may vary on different datasets and domains.
10. Reinforcement learning methods could be explored to improve controlled response generation in future work.

Keywords:
- Task-oriented dialogue systems
- Dialogue act model
- Latent representations
- Pre-training
- Response generation
- Controllable responses
- MultiWOZ dataset
- Zero-shot prediction
- Low-resource settings
- Reinforcement learning