Prompt Middleware: Mapping Prompts for Large Language
Models to UI Affordances
Stephen MacNeil
Temple University
Philadelphia, PA, USA
stephen.macneil@temple.eduAndrew Tran
Temple University
Philadelphia, PA, USA
andrew.tran10@temple.eduJoanne Kim
Temple University
Philadelphia, PA, USA
joanne.kim@temple.edu
Ziheng Huang
University of California—San Diego
La Jolla, CA, USA
z8huang@ucsd.eduSeth Bernstein
Temple University
Philadelphia, PA, USA
seth.bernstein@temple.eduDan Mogil
Temple University
Philadelphia, PA, USA
daniel.mogil@temple.edu
Figure 1: Three methods to connect user interface components to large language models. 1) static prompts are predefined
prompts that can be selected directly from the UI, 2) template-based prompts generate prompts based on selected options in
the UI, 3) free-form prompts provide a direct way of interacting with prompts.
KEYWORDS
large language models, prompt middleware, prompt programming
1 ABSTRACT
To help users do complex work, researchers have developed tech-
niques to integrate AI and human intelligence into user interfaces
(UIs). With the recent introduction of large language models (LLMs),
which can generate text in response to a natural language prompt,
there are new opportunities to consider how to integrate LLMs into
UIs. We present Prompt Middleware, a framework for generating
prompts for LLMs based on UI affordances. These include prompts
that are predefined by experts (static prompts), generated from
templates with fill-in options in the UI (template-based prompts),
or created from scratch (free-form prompts). We demonstrate this
framework with FeedbackBuffet, a writing assistant that automati-
cally generates feedback based on a user’s text input. Inspired by
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
UIST 2022, Oct 20–Nov 2, 2022, Bend, Oregon
©2022 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-XXXX-X/18/06.prior research showing how templates can help non-experts per-
form more like experts, FeedbackBuffet leverages template-based
prompt middleware to enable feedback seekers to specify the types
of feedback they want to receive as options in a UI. These options
are composed using a template to form a feedback request prompt
to GPT-3. We conclude with a discussion about how Prompt Mid-
dleware can help developers integrate LLMs into UIs.
2 INTRODUCTION
Previous research has demonstrated ways that intelligence can
be integrated into UI [ 2,4,13,15,19]. In ‘Wizard of Oz’ systems,
an expert manually controls UI features to simulate an intelligent
user interface [ 4,19]. Similarly, crowdsourcing systems, such as
Soylent [ 2], integrate crowdworkers to power UIs through crowd
workflows [ 13,15]. Finally, specialized machine learning models
have also been trained for a specific task and then embedded into
systems and interfaces [ 23]. Across these systems, rules, heuristics,
workflows, and specialized models guide the ways that interface
affordances can be enhanced with intelligence.
Recent advances in natural language processing have resulted
in large language models (LLMs), such as GPT-3 [ 3], which have
the ability to understand natural language prompts and generate
relevant text responses. These models are already being used to
facilitate creative work [ 5,6,9,20,27]. However, it is not yet cleararXiv:2307.01142v1  [cs.HC]  3 Jul 2023UIST 2022, Oct 20–Nov 2, 2022, Bend, Oregon MacNeil et al.
how to best integrate LLMs into existing UI. In this paper, we
explore three methods for integrating LLMs into UI using prompts
that are predefined by experts (static prompts), generated from
templates with fill-in options in the UI (template-based prompts),
or created from scratch (free-form prompts). These three techniques
for integrating LLMs into UIs, which we call Prompt Middleware,
provide varying amounts of control and guidance to users over
the underlying prompt generation process. We demonstrate the
concept of Prompt Middleware by developing FeedbackBuffet, a
writing assistant that generates feedback for users by guiding them
through a menu of feedback options allowing them to determine
the type of feedback they would like to receive. FeedbackBuffet
implements the ‘template prompt’ middleware to package these
feedback options into a prompt for GPT-3.
3 PROMPT MIDDLEWARE: CONNECTING UI
AFFORDANCES TO LLMS
Crafting high-quality prompts is challenging [ 11,22]. To help peo-
ple create high-quality prompts, PromptMaker guides users to cre-
ate their own prompts with templates and procedural guidance [ 11].
Another approach called AI Chaining simplifies a complex prompt-
ing process by splitting a request into smaller requests which are
individually prompted and then stitched back together [ 24]. This
approach was shown to improve performance and transparency.
Where previous work has focused on making prompt engineer-
ing easier, these approaches have not yet addressed two crucial
aspects: 1) techniques to scaffold domain expertise into the prompting
process, and 2) directly integrating LLMs into user interfaces. We pro-
pose Prompt Middleware as a framework for achieving these two
goal by mapping options in the UI to generate prompts for an LLM.
Prompt Middleware acts as a middle layer between the LLM and
the UI, while also embedding domain expertise into the prompting
process. The UI abstracts away the complexity of the prompts and
separates concerns between a user completing their tasks and the
prompts that might guide LLMs to help them in those tasks. Sum-
marized in Figure 1, the following sections introduce three Prompt
Middleware types: static, template-based, and free-form.
3.1 Static prompts leverage best practices
Prompt engineering and few-shot learning are common techniques
to improve the quality of responses from LLMs [ 22]. We propose the
concept of static prompts as a method for making these best practices
available to users in a UI. A static prompt is a predefined prompt
generated by experts through prompt engineering to achieve high-
quality responses from an LLM. As shown in Figure 1, static prompts
can be hidden behind a button in a UI to send a predefined prompt
to an LLM on behalf of the user. This allows users to tap into best
practices with minimal effort but at the cost of giving up control of
prompt generation.
3.2 Template-based prompts provide flexibility
Previous researchers have shown how expertise and best prac-
tices can be directly embedded into templates to guide crowdwork-
ers [ 12], non-experts [ 10,17,18,28], and even experts [ 8] to do
better work. For example, Motif, a video storytelling application,
leverages storytelling patterns to guide users’ story creation [ 12].Inspired by how templates can guide people, we explore how expert
templates might similarly guide LLMs. We propose template-based
prompts as a method for generating prompts by filling in a pre-
made template with options from a user interface. The template
and user interface can integrate expertise and best practices while
giving users more control through options in the UI.
3.3 Free-form prompts provide full control
Previous research shows that developing free-form prompts can
be challenging [ 11]. However, experts can generate high-quality
prompts through the process of prompt engineering. Providing
users with full control of the prompting process may be desired in
some cases. Free-form prompts provide full access to users as they
design their prompt from scratch.
4 CASE STUDY
The case study methodology is a technique for illustrating an idea
through the use of examples [ 26]. To engage more deeply with the
concept of Prompt Middleware, we developed the FeedbackBuffet
prototype which implements the template-based prompting design
pattern. This case study illustrates what template-based prompting
might look like when implemented in a user interface.
4.1 FeedbackBuffet System
FeedbackBuffet is a writing assistant that allows users to request
automated feedback for any writing sample, such as an essay, email,
or statement of purpose, based on UI options. As shown in Fig-
ure 2, UI options offer users relevant feedback options which are
combined using a template to form a prompt for GPT-3. The tem-
plate integrates best practices of feedback design and cues the feed-
back seeker to consider qualities of good feedback. FeedbackBuffet
implements the template-based prompt middleware to integrate
intelligence into the interface.
4.1.1 System Implementation. The system is implemented as a
ReactJS web app. The prompts are generated through template
literals (i.e.: string interpolation) where each selected option from
the UI is injected into the template to form a string that is sent as a
prompt to OpenAI via API calls using zero-shot learning.
4.1.2 Integrate Best Practices in Feedback Design. There are prin-
ciples and best practices for feedback design, such as asking a
clarifying question and then making a statement [ 16], sandwiching
criticism between two positive comments [ 7], and making feedback
actionable [ 14]. The feedback template used by FeedbackBuffet
is based on a feedback framework that includes valence, level of
abstraction, and feedback type [ 1], summarized in Figure 2. We
present examples of the feedback generated by GPT-3 using our
template in Figure 3.
4.2 Use Case: Requesting Design Feedback
To illustrate how FeedbackBuffet operates, we present the following
use case about Sasha, a CS student who is taking career prepara-
tory course to work on his statement of purpose. Sasha completes
a first draft of his statement and he receives feedback from his
instructor that critiques the structure—Sasha did not start with a
strong motivation. He focused too much on the graduate programPrompt Middleware UIST 2022, Oct 20–Nov 2, 2022, Bend, Oregon
Figure 2: FeedbackBuffet enables users to insert writing samples (1) and select from a set of predefined options for the type of
feedback they want to receive (2). Using a template, these options are combined to form a prompt (3) which is sent to GPT-3
using OpenAI’s public API (4). GPT-3 then generates feedback, which is displayed in a text box for the user to review (5).
before motivating the reader. After adding motivation based on
his journey into computers, he uses FeedbackBuffet to get more
feedback before his next class. He pastes his statement into the in-
put area and selects options to request feedback about the content
of this draft. These options along with his draft are packaged as a
prompt and then sent to GPT-3. He receives the feedback shown
in Figure 2. Based on this feedback, Sasha edits his statement to
add more specific details about how he learned to code by forming
an informal group with his friends. He continues to iterate on his
statement of purpose, periodically referring back to FeedbackBuffet,
and he is excited to show his progress to his instructor.
5 DISCUSSION
In this paper, we build on existing research [ 2,10,17,18,21] for
integrating expertise and intelligence into UIs. We introduce the
Prompt Middleware Framework to guide the process of integrating
LLMs into a UI. We demonstrate this vision with FeedbackBuffet, a
intelligent writing assistant that automatically generates feedback
based on text input. Given that previous attempts at integrating
intelligence may require effort to acquire intelligence sources or be
costly, FeedbackBuffet offers a lightweight method for integrating
intelligence and best practices into a UI. FeedbackBuffet’s UI acts
as a facade around the LLM, abstracting away the complexity of
interacting with LLMs. While FeedbackBuffet currently focuses on
template-based prompts, we could include static prompts as well.
For example, with a button titled ‘Pros and Cons’, which would
send the prompt shown in Figure 1 to an LLM.Researchers have identified several challenges individuals face
when interacting with general purpose AI, such as a lack of aware-
ness about the AI’s capabilities which can lead them to request
overly complicated on non-existent tasks from the AI agent [ 25].
Researchers are still developing an understanding of the capabil-
ities of LLMs, but in this paper we show it is possible to convey
known possibilities afforded by LLMs through a UI. Through static
prompts, users can use prompts that have been engineered by ex-
perts to be effective. Through template-based prompts, they can
choose from a list of menu options to generate prompts that have
been previously tested by experts. This ability to communicate the
capabilities afforded by LLMs has the potential to make them more
accessible for non-experts.
As future work, we plan to evaluate three systems, including
FeedbackBuffet, that embody these three types of prompt middle-
ware to understand how best to integrate LLMs into existing UI.
Through this evaluation, we also hope to develop a better under-
standing of how much control is desired when interacting with
LLMs through UI. While complete control in the form of free-form
prompts might be desired in some contexts, it likely depends. For
example, a feedback system based on static prompts, which provide
less control, may simplify the feedback request process.
6 CONCLUSION
In this paper, we present FeedbackBuffet, a writing assistant that
generates feedback on writing samples using GPT-3. The user can
choose from a set of feedback options that are combined using a
template to form a prompt for GPT-3. This system demonstratesUIST 2022, Oct 20–Nov 2, 2022, Bend, Oregon MacNeil et al.
how templates can serve as middleware to map affordances in a
user interface to prompt a large language model. This work serves
as an initial step toward developing a prompt middleware that can
bridge the gap between users and large language models.
