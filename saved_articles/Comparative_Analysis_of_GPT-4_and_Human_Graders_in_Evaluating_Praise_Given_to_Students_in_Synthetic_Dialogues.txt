arXiv:2307.02018v1  [cs.CL]  5 Jul 2023Comparative Analysis of GPT-4 and Human
Graders in Evaluating Praise Given to Students
in Synthetic Dialogues
Dollaya Hirunyasiri, Danielle R. Thomas, Jionghao Lin, Kenneth R. Koed inger,
and Vincent Aleven
Carnegie Mellon University, Pittsburgh, PA, USA
dhirunya@andrew.cmu.edu
{Drthomas,Jionghao,Koedinger }@cmu.edu
aleven@cs.cmu.edu
Abstract. Research suggests that providing speciﬁc and timely feed-
back to human tutors enhances their performance. However, i t presents
challenges due to the time-consuming nature of assessing tu tor perfor-
mance by human evaluators. Large language models, such as th e AI-
chatbot ChatGPT, hold potential for oﬀering constructive f eedback to
tutors in practical settings. Nevertheless, the accuracy o f AI-generated
feedback remains uncertain, with scant research investiga ting the ability
of models like ChatGPT to deliver eﬀective feedback. In this work-in-
progress, weevaluate 30dialogues generated byGPT-4inatu tor-student
setting. We use two diﬀerent prompting approaches, the zero -shot chain
of thought and the few-shot chain of thought, to identify spe ciﬁc com-
ponents of eﬀective praise based on ﬁve criteria. These appr oaches are
then compared to the results of human graders for accuracy. O ur goal is
to assess the extent to which GPT-4 can accurately identify e ach praise
criterion. We found that both zero-shot and few-shot chain o f thought
approaches yield comparable results. GPT-4 performs moder ately well
in identifying instances when the tutor oﬀers speciﬁc and im mediate
praise. However, GPT-4 underperforms in identifying the tu tor’s ability
to deliver sincere praise, particularly in the zero-shot pr ompting scenario
where examples of sincere tutor praise statements were not p rovided.
Future work will focus on enhancing prompt engineering, dev eloping a
more general tutoring rubric, and evaluating our method usi ng real-life
tutoring dialogues.
Keywords: Tutor Feedback ·Tutor Evaluation ·Math tutors ·Real-
time Feedback ·Tutor Training ·ChatGPT ·GPT-4
1 Introduction
Tutoringis amongthe most highly personalizedand consistentlyimpac tful inter-
ventions known to improve student learning [10, 16]. Despite the kno wn positive
impacts of tutoring on student learning, there is a known shortage of trained
tutors, with many available tutors lacking experience and the neces sary com-
petency skills to be successful in the ﬁeld [21]. In recent years, alth ough tutor2 Dollaya et al.
training programs have been developed, most do not provide tutor s with speciﬁc
formative feedback during training, and little research exists on tu tors receiving
speciﬁc feedback on their actual tutoring practices. Recent adv ances in pre-
trained large language models, such as the well-known AI-chatbot C hatGPT,
have made it possible to provide speciﬁc and explanatory feedback t o learners
[1]. We propose that the use of large language models to provide tuto rs with
eﬀective formative feedback on their actual tutoring is a promising use case.
The ability of GPT-4 to accurately evaluate components of praise giv en to
students, which canbe determined bycomparingit tohuman expert evaluations,
is a critical component of providing eﬀective feedback, and as such , serves as
our starting point. Moreover, the accuracy of AI-generated tu tor feedback for
the purpose of improving tutor learning and performance has not b een well
researched, if at all. In this work-in-progress, we used simulated d ialogues to
assess the capability of GPT-4 in providing accurate feedback to hu man tutors
regarding their delivery of eﬀective praise to students. To this end , the primary
research question addressed is:
RQ:CanGPT-4accuratelyassesscomponentsofeﬀectivehumantuto r’spraise
to students and, in particular, what is the comparative accuracy b etween
zero-shot and few-shot chain of thought prompting approaches ?
2 Related Work
2.1 High-Quality Feedback
Feedback is one of the most powerful inﬂuences on student achiev ement and can
signiﬁcantly impact learning outcomes and performance [19, 8, 13]. E ﬀective
feedback is described as having many characteristics, particularly : 1) being tar-
geted, linked to speciﬁc goals and learning objectives; 2) being prog ress-oriented
andconstructive,focusingonthelearningprocessandsupportin gagrowthmind-
set; 3) being timely, as providing immediate and frequent feedback o ften bene-
ﬁts students’ academic performance [19, 7, 4]. However, provid ing learners with
timely, explanatory feedback, or in this case, oﬀering timely feedba ck to on-
line tutors while they are actively tutoring students is laborious and e xpensive
when using human evaluators [3]. To facilitate the feedback provision process,
Demszky et al.[4] provide automated, individualized feedback to over one thou-
sand instructors on their teaching sessions within an online compute r course.
Instructors received the feedback via email within 2-4 days. This a utomatic, for-
mative feedback tool improved instructors’ uptake of student c ontributions by
27%,with preliminaryevidencesuggestingit alsoincreasedstudents ’ satisfaction
with assignments and the course itself [4]. These promising ﬁndings un derscore
the potential that more timely feedback—either occurring in real t ime or shortly
after—a tutoring session could enhance student contribution and performance.
Despite the known positive impact of feedback on educators’ perf ormance and
the global interest in leveraging large language models (LLMs) for co mmunica-
tive tasks, there is currently a lack of research on the use of LLMs for generating
feedback on tutoring.Title Suppressed Due to Excessive Length 3
2.2 Tutoring Competencies & Giving Eﬀective Praise
There is limited research on the key competencies and components o f eﬀective
tutoring [2], with many qualities of impactful tutoring challenging to me asure
or assess (e.g., building a relationship with the student) in practice. T he Na-
tional Student Support Accelerator (2021), a think tank emanat ing from the
Annenberg Institute at Brown University that focuses on dissemin ating research
and advancing developments in tutoring, has created a rubric for e valuating the
eﬀectiveness of tutors in facilitating sessions. The rubric contains three main
criteria for assessing a tutoring session: 1) The tutor eﬀectively e mploys tutor-
ing facilitation strategies; 2) The tutor identiﬁes and addresses po tential student
misconceptions or confusions; and 3) The tutor explains content c learly and cor-
rectly. Each criterion is measured on a 1-5 Likert-like scale, from “lacking” to
“exemplary” , respectively [17].
Ourrecentresearch,surveying18partneringmembersacrosss everaltutoring
organizations,determined that the most importantperceivedtut oring skillswere
the ability to engage and motivate students and build successful re lationships
with them [2]. From this research, we developed a super competency frame-
work called SMART, standing for S ocial-emotional learning, M astering content,
Advocacy, R elationships, and T echnology. Mastering Content, which pertains to
a tutor’s ability to comprehend mathematical pedagogy and apply eﬀ ective tu-
toring skills, was identiﬁed as a crucial element of eﬀective tutoring. Within this
dimension, there are multiple scenario-based lessons covering a ran ge of content.
We selected the lesson titled Giving Eﬀective Praise as our starting point, given
its critical role in fostering and maintaining student motivation and en gagement.
The lesson objectives from Giving Eﬀective Praise state that upon completion
of the lesson, tutors will be able to: explain how to increase student motivation
by giving eﬀective praise; identify features of eﬀective praise; and apply strate-
gies by responding to students through praise [21]. Tutors should s trive to praise
students for their eﬀort, acknowledging the learning process, an d not necessar-
ily the outcome, such as getting the problem correct [5]. The ﬁve key criteria
for productive, process-focused praise used as a rubric in this wo rk state that
praise is: 1) sincere, earned, and truthful; 2) speciﬁc by giving det ails of what
the student did well; 3) immediate, with praise given right after the st udent’s
action; 4) authentic, not repeated often; and 5) focused on the learning process,
not ability [21].
Given the known importance of eﬀective praise on student motivatio n and
performance, can large language models like GPT-4 pick up on the use of these
strategieswhen analyzingtutor-student interaction data (i.e., tu tor-student chat
logs or transcripts)? If so, this would open the door to using large la nguage
models, such as GPT-4, to generate timely, impactful, and formativ e feedback
to tutors during their actual tutoring sessions.
2.3 Using Large Language Models to Give Feedback
Large language models (LLMs) are trained using deep learning to pro duce text
that resembles human writing. Trained on a vast array of sources, such as4 Dollaya et al.
Wikipedia, webpages, written materials, and practicallyanything cur ated on the
internet,thetextgeneratedbyneuralLLMsoftenmirrorsthew rittenlanguageof
most humans. We focus on ChatGPT using GPT-4, a general pre-tr ained large
multimodal model capable of accepting both image and text inputs. O penAI
[18] asserts, “while less capable than humans in real-world scenarios, [G PT-4]
exhibits human-level performance on various professional and academic bench-
marks.”Thiscurrentinvestigationseekstodetermineifidentifyingtutors’ ability
to give eﬀective praise to students is an academic benchmark within G PT-4’s
capabilities.
TheapplicationofLLMstoprovidefeedbackisagrowingresearchar eawithin
education [3], with researchers striving to identify the limits of these models’ ca-
pabilities. The use of LLMs to provide direct feedback to students, rather than
tutors, has been explored by many researchers using various pre -trained models.
For example, Jai et al.[9] used BART and found that AI-generated feedback
was near-human in performance, while Li and Xing [11], employing GPT- based
models, concluded that providing emotional support via contextua l replies to
learners in massive open online courses (MOOCs) was comparable to h umans.
In a study more closely aligned with our current work, Dai et al.[3] demon-
strated that ChatGPT was more capable than human instructors a t genera -
ting detailed feedback that ﬂuently summarizes students’ perfor mance. Despite
these promisingﬁndings involvingLLM’s ability to providefeedback to s tudents,
there exists very little research on its application to tutor feedbac k. Thomas et
al.[20] leveraged ChatGPT to generate synthetic tutor responses f rom real-
life tutoring scenarios within the previously discussed lesson, Giving Eﬀective
Praise. Thomas et al.[20] found that human-created training sets outperformed
AI-generated training sets for creating automated short answe r grading sys-
tems, with ChatGPT-generated tutor responses often lacking th e nuance and
variety evident within human-sourced tutor responses. Neverth eless, leveraging
ChatGPT to evaluate human tutors’ eﬀectiveness in giving praise to students
represents an interesting and novel use case.
2.4 Prompt Engineering
Prompt engineering, also known as in-context prompting, is the str ategic cre-
ation and ﬁne-tuning of prompts aimed at guiding a language model’s be hav-
ior to yield speciﬁc outcomes. This process is achieved without the ne cessity
of modifying the model’s inherent architecture or parameters. As a n empiri-
cal ﬁeld, prompt engineering necessitates extensive experimenta tion and testing,
considering the variations in the outcomes generated by identical p rompts across
diﬀerent models [23]. Chain-of-Thought (CoT) prompting is a techn ique that
breaks down complex, multi-step problems into more manageable, int ermediate
steps. This process aids language models in following a logical sequenc e, where
each subsequent prompt builds upon the prior one, thus stimulating reasoning.
Within the context of CoT prompting, two key methodologies exist: z ero-shot
andfew-shotprompting.Zero-shotCoTpromptingisastandalone approachthat
relies solely on the instructions embedded within the prompt. Conver sely, few-
shot CoT prompting incorporates examples to instruct the model o n generatingTitle Suppressed Due to Excessive Length 5
appropriate responses. Zero-shot and few-shot prompting are two fundamental
approaches often championed in numerous large language model (L LM) studies,
commonly employed for benchmarking LLM performance [23, 12].
3 Method
3.1 Creation of Synthetic Tutoring Dialogues
Due to the limited availability of real-life tutor-student dialogues, we u sed syn-
thetic chat logs generated by prompting GPT-4. While we acknowledg e the ne-
cessity of validating our ﬁndings with real-life dialogues, the current study is
useful as a proof of concept and serves as a simulation or model, pe nding access
to real-life tutor-student dialogues. We used GPT-4 to generate 3 0 synthetic
tutor-student dialogues. Among these dialogues, the average nu mber of words
per dialogue was 253 (SD = 45.0) ; the tutor’s words per dialogue averaged 180
(SD = 38.6) ; and the student’s words per dialogue averaged 56.8 (SD = 23.7) .
Due to the limited space, we attached other prompting strategies a nd synthetic
tutoring dialogues in the digital appendix1. An example of a tutor-student dia-
logue generated by GPT-4 is shown in the Example 1:
Example 1. An example of synthetic tutor-student dialogue generate d by GPT-4
Tutor:Good evening! Let’s start with this problem. “Last week 24,0 00 fans attended
a football match. Three times as many bought tickets this wee k, but one-sixth of them
canceled their tickets. How many are attending this week?”
Student: I think we need to ﬁrst calculate three times the fans from las t week, right?
Tutor:Absolutely, you’re on the right track! Now, how much does tha t make?
Student: That would be 72,000.
Tutor:Excellent multiplication! Yes, you’re correct. Now, remem ber one-sixth of them
canceled their tickets. What should we do next?
Student: We need to subtract one-sixth of 72,000 from 72,000.
Tutor:That’s right! I see you’ve clearly grasped the concept of fra ctions. Could you
calculate it for me?
Student: The answer should be 60,000.
3.2 Human Grader Identiﬁcation of Praise Criteria
To evaluate the accuracy of GPT-4, we initially recruited three huma n graders,
each with over ﬁve years of teaching experience. These graders w ere tasked with
identifying eﬀective praise within synthetic tutoring dialogues. Befo re beginning
this task, they each completed a lesson titled Giving Eﬀective Praise . This lesson
clearly deﬁnes eﬀective praise and trains learners on how to apply it. Addition-
ally, the human graderswere provided with a rubric that includes ﬁve criteria for
1https://github.com/DollayaDollayaDollaya/AIEDWorksh op6 Dollaya et al.
identifying the diﬀerent aspects of praise. This rubric, proposed b y [21] (intro-
ducedinSection2.2),includesﬁvekeycriteriaandtheirnotation(inp arenthesis)
are, as follows: Praise is: 1) sincere, earned, and truthful (Sincere) ; 2) speciﬁc by
giving details of what the student did well (Speciﬁc) ; 3) immediate, with praise
given rights after the student’s action (Immediate) ; 4) authentic, not repeated
often(Authentic) ; and 5) focused on the learning process, not ability (Process-
focused). Toarriveat the ﬁnal gradingforeachdialogue,we usedmajorityv oting
among the human graders. For instance, if two or more graders as sessed that a
particular chat log did not meet criterion 1 (Sincere) , we followed their consen-
sus and regarded that as the ground truth. Finally, we employed Fle iss’ Kappa
[6] to measure the inter-rater reliability among the three human gra ders (shown
in Table 1).
Table1. Agreement among threehumangraders on identifying prais e criteria proposed
by [21].
Praise Criteria Agreement score Fleiss’ Kappa Interpretat ion
1-Sincere 84.44% 0.60 Moderate
2-Speciﬁc 73.33% 0.44 Moderate
3-Immediate 68.89% 0.34 Fair
4-Authentic 88.89% 0.69 Substantial
5-Process-focused 64.44% 0.29 Fair
3.3 Prompting GPT-4 to Identify Praise Criteria
We prompted GPT-4 to identify instances of praise in the dialogues ba sed on
the speciﬁc criteria provided. Recognizing that the eﬀectiveness o f GPT-4 is
largely inﬂuenced by the prompt engineering strategies used, we imp lemented
two approaches: zero-shot and few-shot Chain of Thought (CoT ) prompting.
This generated two sets of results. These results were then comp ared to the
assessments made by human graders, using precision, recall, and F 1 scores as
metrics. Due to space constraints, we have included the zero-sho t CoT and few-
shot CoT prompts in the digital appendix.
4 Results
4.1 Comparison of GPT-4 and Human Grader Performance
We compared the results from GPT-4, using both zero-shot CoT an d few-shot
CoT prompting, with the consensus results from the human grader s. The results
are presented in Table 2. Both the zero-shot CoT and few-shot Co T approaches
performed well in detecting elements of speciﬁcpraise (i.e., detailing what the
student did well) and immediate praise (i.e., given right after the student’s ac-
tion). We posit that the relative straightforwardness and clear na ture (i.e., theTitle Suppressed Due to Excessive Length 7
tutor either delivered praise immediately after the student’s action or they did
not) of criterion 2 and 3, speciﬁcandimmediate praise respectively, make them
easier to detect by GPT-4 and human graders when present, comp ared to the
remaining criteria. Both the zero-shot and few-shot CoT promptin g methods for
detecting speciﬁcpraise had the lowest performance comparison between GPT-4
and the human graders, with F1 scores of 0.54 and 0.67, respective ly.
Table2. The comparison of the performance of GPT-4 and the consens us of hu-
man graders using both zero-shot and few-shot CoT prompting methods, as illustrated
through precision, recall, and F1 scores by praise criteria , demonstrated good perfor-
mance in detecting speciﬁc and immediate praise criteria.
Praise CriteriaZero-shot CoT Few-shot CoT
Precision Recall F1 score Precision Recall F1 score
1-Sincere 0.37 1.00 0.54 0.50 1.00 0.67
2-Speciﬁc 0.75 0.92 0.83 0.85 0.85 0.85
3-Immediate 0.75 0.90 0.82 0.72 0.90 0.80
4-Authentic 0.60 1.00 0.75 0.63 0.83 0.71
5-Process-focused 1.00 0.50 0.67 1.00 0.50 0.67
4.2 Comparison of Zero-shot and Few-shot Prompting
The performance of zero-shot and few-shot CoT prompting meth ods showed a
signiﬁcant degree of similarity. To quantitatively assess the inter-r ater agree-
ment between these two approaches, we utilized Cohen’s kappa sta tistical mea-
sure. The analysis in Table 3 showed a substantial level of agreemen t between
the zero-shot and few-shot CoT prompting techniques, suggest ing a strong con-
sistency in their performance. Speciﬁcally, there was nearly perfect agreement
(93.33%) in identifying authentic andprocess-focused praise criteria, with sub-
stantial agreement in recognizing sincereandspeciﬁcpraise.
Table3. Inter-rater reliability between zero-shot and few-shot CoT prompting meth-
ods. Notice near perfect agreement for the detection of authentic andprocess-focused
praise criteria.
Praise Criteria Agreement score Cohen’s Kappa Interpretat ion
1-Sincere 83.33% 0.66 Substantial
2-Speciﬁc 90.00% 0.80 Substantial
3-Immediate 83.33% 0.44 Moderate
4-Authentic 93.33% 0.84 Near perfect
5-Process-focused 93.33% 0.85 Near perfect8 Dollaya et al.
4.3 Strengths and Weaknesses of GPT-4 Across Praise Criteri a
In reference to Table 2, it’s evident that GPT-4 performed well in ide ntifying
speciﬁc and immediate typesofpraise,asindicated bythe favorable performance
measures(F1 >80%).Examples2,3,and4illustrateselectedtutordialoguesand
responses generated by GPT-4 using few-shot CoT prompting tha t align with
the majority decision of the human graders. It’s worth noting that we chose
to highlight criteria 2 ( Speciﬁc), 3 (Immediate ), and 4 ( Authentic ), which have
relatively high F1 score.
Example 2. Does not meet criterion 2 (speciﬁc)
Tutor:What a superstar! Your intellectual prowess is unmatched.
GPT-4’s rationale: The praise is overlybroadanddoesn’t givespeciﬁc details a bout
what the student did well. The student merely agreed with the tutor [dialogue not
shown], and the tutor’s response is disproportionate.
Example 3. Meets criterion 3 (immediate)
Student: Oh, I see. I should have multiplied it by 100, not 50. I’ll reme mber that
next time.
Tutor:That’s the spirit! I’m really impressed with your enthusias m to learn from
your mistakes. Keep it up!
GPT-4’s rationale: The tutor praises the student’s willingness to learn immedi ately
after the student admits their mistake and expresses an inte ntion to remember the
correct method for the future.
Example 4. Does not meet criterion 4 (authentic)
Tutor:Oh, you are such a genius! You are so fast and responsive. Your ability to
pick an answer quickly is absolutely admirable.
[Tutor and student talking.]
Student: ...But... I just agreed with you.
Tutor:That’s right! You agreed correctly...
Student: Multiply?
Tutor:Brilliant! Absolutely brilliant! Your mathematical mind i s truly something to
behold. You are a natural-born mathematician. It’s amazing !
Student: I’m just guessing
Tutor:And what an excellent guess it was!...
GPT-4’s rationale: The tutor repeats similar forms of praise multiple times, ma king
the praise feel less authentic and repetitive.
Then, we examined instances where GPT-4 disagreed with the major ity of
human graders, underperforming in its ability to detect diﬀerent pr aise criteria.
We focused on criteria 1 ( sincere) and 5 ( process-focused ), for which GPT-4
received F1 score of 0.67, lower than the other criteria. In Example 5 below,
after the student provided three incorrect responses before e ventually arrivingat
the correctanswer, human gradersinterpreted the subsequen t praise as insincere
(criteria 1), contending that the student’s achievement didn’t ent irely warrant
the commendation. In contrast, GPT-4 failed to incorporate this c ontext intoTitle Suppressed Due to Excessive Length 9
its evaluation. It seemingly focused solely on the immediate conversa tion,noting
that the student had provided a correct answer, and concluded t hat the praise
was therefore sincere and deserved. In Example 6, GPT-4 misinter preted the
tutor’s praise for the student’s eﬀorts. The tutor’s compliment, i.e .,“You’re
showing a keen ability to recollect and apply important math ematical principles,”
was interpreted by GPT-4 as praise for ability, due to the inclusion of the term
“ability”. However, human graders perceived this compliment as being direct ed
towards the learning process. In this regard, GPT-4’s interpreta tion deviated
from the human graders’ consensus.
Example 5. Human-grader majority says it does not meet criterion 1 (sincere) , but
GPT-4 says it does meet
Student: Ok. I think it is... A?
Tutor:Good start! (...) However, the result doesn’t match the expe cted value.
Student: Ok, I’ll try again. Maybe it’s D?
Tutor:(...) Unfortunately, it’s not equation D either. But, your p erseverance is really
commendable.
Student: I see. What about C?
Tutor:That’s a good guess too. Unfortunately, it’s not equation C e ither. However,
your willingness to keep guessing and learning from your mis takes is extremely praise-
worthy.
Student: Oh... okay. So it must be B then.
GPT-4’s rationale: The tutor sincerely appreciates the student’s eﬀort and per se-
verance. The praise is based on the student’s actual actions .
Example 6. Human-grader majority says it meets criterion 5 (process-focused) but
GPT-4 says it does not meet
Tutor:You’re showing a keen ability to recollect and apply importa nt mathematical
principles.
GPT-4’s rationale: The tutor’s praise focuses on the student’s ability, rather than
speciﬁcally praising their learning process.
5 Discussion
GPT-4 exhibitedproﬁciency in detectingspeciﬁcand immedi atepraise,
but it struggled to recognize sincerity. We hypothesize that GPT-4’s su-
perior performance in detecting speciﬁcandimmediate praise is due to the
relatively straightforward criteria for these types, while assessin g sincerity in
praise statements demands more nuanced judgment and perhaps a greater level
of social-aﬀective understanding (e.g., politeness [14, 15]), which hu man graders
possess.WenoticedthatitwasparticularlychallengingforGPT-4to identifysin-
cerity,especiallyduring the zero-shotCoTprompting.By including n uancedand
varied examples of tutor praise statements, deemed sincere by hu man graders,
in few-shot prompting strategies, we might enhance GPT-4’s perfo rmance in
recognizing this type of praise.10 Dollaya et al.
Both zero-shot and few-shot CoT prompting exhibited comparable perfor-
mance. Zero-shot and few-shot learning methods demonstrated similar results,
with both falling short in detecting sincerity in praise (with F1 scores o f 0.54
and 0.67, respectively) compared to their performance on other p raise criteria.
Various techniques for ﬁne-tuning language models exist, particula rly for zero-
shot learning, such as instruction tuning [22]. Therefore, further research into
enhancing zero-shot and few-shot learning methods is necessary to improve the
performance of both models.
5.1 Limitations
The current study has several limitations. First, the lack of availab ility of real-
life tutor-student conversations is a considerable limitation. Synth etic dialogues,
while useful for preliminary investigation, do not entirely capture th e complexity
and nuances of authentic tutor-student interactions. Second, the sample size of
the dialogues used in this study may limit the generalizability of the ﬁndin gs.
We used only 30 synthetic dialogues for this study, and increasing th is number
would likely improve the reliability and robustness of our ﬁndings. Third , the
few-shotpromptsweutilizedwererelativelysimpleandincludedalimited variety
of examples. By integrating a wider range of nuanced examples, we m ight boost
GPT-4’s capability to match human graders’ discernment of praise c riteria that
are more nuanced and socially sensitive.
5.2 Implications for Future Work
The present work sets a precedent for potential expansions. Fir stly, we aim to
address existing limitations by incorporating real-life dialogues, incre asing the
volume of chat logs, and enhancing the eﬀectiveness of zero-shot and few-shot
prompting methods. Secondly. the scope could be broadened by ev aluating dia-
logues using a more comprehensive, high-level tutoring rubric. This would move
away from focusing solely on speciﬁc tutoring skills such as delivering e ﬀective
praise to students. As previously discussed, and recommended by the National
Student Support Accelerator [17] for adoption by tutoring organ izations, the
holistic tutoring rubric could lay the groundwork for future eﬀorts in crafting
LLM prompts. These prompts could then provide timely feedback to tutors re-
gardingtheir overallperformance.Thirdly,apartfrominvestigat ingthe accuracy
of GPT-4’s performance, we could delve into other aspects, such a s its reliability
in synthesizing such feedback.
6 Conclusion
In this study, we assigned GPT-4 the task of identifying ﬁve distinct components
of eﬀective praise from synthetic tutor-student dialogues, acco rding to past re-
search determining criteria of eﬀective praise. Our results sugges t that GPT-
4 performs moderately well in identifying two of these criteria: spec iﬁc praise
(whichprovidesdetailonwhatthestudentdidwell)andimmediatepra ise(whichTitle Suppressed Due to Excessive Length 11
is delivered right after the student’s action). Conversely, GPT-4 h ad less success
in recognizing instances of process-focused and sincere praise fr om the tutor.
Overall, zero-shot and few-shot chain of thought prompting meth ods performed
similarly. However, we anticipate enhancements to few-shot chain- of-thought
prompting techniques, in particular, more nuanced and socially-res ponsive ex-
amples ofsincerepraisecriteriawill improvethe performanceofGPT -4to detect
praise closer to that of human graders.
Acknowledgments.
This work is supporting with funding from the Richard King Mellon Found ation
(Grant#10851)and the Heinz Endowments(E6291).Any opinions, ﬁndings,and
conclusions expressed in this material are those of the authors. A dditionally,
thanks Sorawit Saengkyongam, Can Udomcharoenchaikit, and Maim Hoque for
contributing their thoughts on this research.
Bibliography
[1] Chen, W., Ma, X., Wang, X., Cohen, W.W.: Program of thoughts prom pt-
ing: Disentangling computation from reasoning for numerical reaso ning
tasks. arXiv preprint arXiv:2211.12588 (2022)
[2] Chhabra, P., Chine, D., Adeniran, A., Gupta, S., Koedinger, K.: An e val-
uation of perceptions regarding mentor competencies for techno logy-based
personalized learning. In: Society for Information Technology & Te acher
EducationInternationalConference.pp. 1620–1625.Associat ionforthe Ad-
vancement of Computing in Education (AACE) (2022)
[3] Dai, W., Lin, J., Jin, F., Li, T., Tsai, Y.S., Gasevic, D., Chen, G.: Can large
language models provide feedback to students? a case study on ch atgpt
(2023)
[4] Demszky, D., Liu, J., Hill, H.C., Jurafsky, D., Piech, C.: Can automate d
feedback improve teachers’ uptake of student ideas? evidence f rom a ran-
domized controlled trial in a large-scale online course. edworkingpap er no.
21-483. Annenberg Institute for School Reform at Brown Univer sity (2021)
[5] Dweck,C.S.:Mindset:Thenewpsychologyofsuccess.Randomho use(2006)
[6] Fleiss, J.L.: Measuring nominal scale agreement among many rater s. Psy-
chological bulletin 76(5), 378 (1971)
[7] Goodwin, B., Miller, K.: Good feedback is targeted, speciﬁc, timely. Edu-
cational Leadership 70(1), 82–83 (2012)
[8] Hattie, J., Timperley, H.: The power of feedback. Review of educa tional
research 77(1), 81–112 (2007)
[9] Jia, Q., Young, M., Xiao, Y., Cui, J., Liu, C., Rashid, P., Gehringer, E.:
Insta-reviewer: A data-driven approach for generating instant feedback on
students’ project reports. International Educational Data M ining Society
(2022)
[10] Kraft, M.A., Falken, G.T.: A blueprint for scaling tutoring and ment oring
across public schools. AERA Open 7, 23328584211042858 (2021)12 Dollaya et al.
[11] Li,C.,Xing,W.:Naturallanguagegenerationusingdeeplearningt osupport
mooc learners. International Journal of Artiﬁcial Intelligence in E ducation
31, 186–214 (2021)
[12] Li, Y., Sha, L., Yan, L., Lin, J., Rakovi´ c, M., Galbraith, K., Lyons, K.,
Gaˇ sevi´ c, D., Chen, G.: Can large language models write reﬂectively . Com-
puters and Education: Artiﬁcial Intelligence 4, 100140 (2023)
[13] Lin, J., Dai, W., Lim, L.A., Tsai, Y.S., Mello, R.F., Khosravi, H., Gasevic,
D., Chen, G.: Learner-centred analytics of feedback content in hig her edu-
cation. In: LAK23: 13th International Learning Analytics and Kno wledge
Conference. pp. 100–110 (2023)
[14] Lin, J., Rakovic, M., Lang, D., Gasevic, D., Chen, G.: Exploring the p o-
liteness of instructional strategies from human-human online tuto ring dia-
logues. In: LAK22: 12th International Learning Analytics and Kno wledge
Conference. pp. 282–293 (2022)
[15] Lin, J., Rakovi´ c, M., Xie, H., Lang, D., Gaˇ sevi´ c, D., Chen, G., L i, Y.: On
the role of politeness in online human–human tutoring. British Journa l of
Educational Technology (2023)
[16] Lin, J., Singh, S., Sha, L., Tan, W., Lang, D., Gaˇ sevi´ c, D., Chen, G.: Is it a
goodmove?miningeﬀectivetutoringstrategiesfromhuman–human tutorial
dialogues. Future Generation Computer Systems 127, 194–207 (2022)
[17] National Student Support Accelerator: Toolkit for tutoring p rograms
(2021),https://doi.org/10.26300/5n7h-mh59
[18] OpenAI: Gpt-4 technical report (2023)
[19] Ryan, T., Henderson, M., Ryan, K., Kennedy, G.: Designing learne r-centred
text-based feedback: a rapid review and qualitative synthesis. As sessment
& Evaluation in Higher Education 46(6), 894–912 (2021)
[20] Thomas, D., Gupta, S., Koedinger, K.: Comparative analysis of lea rner-
sourced human-graded and ai-generated responses for autogr ading online
tutor lessons. In: Artiﬁcial Intelligence in Education. 24th Intern ational
Conference, AIED 2023, Tokyo, Japan July 3–7, 2023. Springer ( 2023)
[21] Thomas, D., Yang, X., Gupta, S., Adeniran, A., Mclaughlin, E., Koed inger,
K.: When the tutor becomes the student: Design and evaluation of e ﬃcient
scenario-based lessons for tutors. In: LAK23: 13th Internatio nal Learning
Analytics and Knowledge Conference. pp. 250–261 (2023)
[22] Wei, J., Bosma,M., Zhao,V.Y., Guu, K., Yu, A.W., Lester, B., Du, N., D ai,
A.M., Le, Q.V.: Finetuned language models are zero-shot learners. ar Xiv
preprint arXiv:2109.01652 (2021)
[23] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi, E., Le, Q., Zhou,
D.: Chain of thought prompting elicits reasoning in large language mode ls.
arXiv preprint arXiv:2201.11903 (2022)This figure "NER_feedback.png" is available in "png"
 format from:
http://arxiv.org/ps/2307.02018v1