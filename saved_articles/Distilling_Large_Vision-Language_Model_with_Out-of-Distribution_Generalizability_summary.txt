Summary:
This paper investigates the distillation of visual representations in large vision-language models into smaller student models using a small- or mid-scale dataset. The study focuses on open-vocabulary out-of-distribution (OOD) generalization, which is a challenging problem. The authors propose two principles to enhance student's OOD generalization: better imitating the teacher's visual representation space and promoting coherence in vision-language alignment, and enriching the teacher's language representations with semantic attributes. The proposed approaches demonstrate significant improvements in student performance on open-vocabulary OOD classification.

Bullet Points:
- Large vision-language models are difficult to deploy on resource-constrained devices and time-sensitive tasks due to their size and computational requirements.
- Model distillation is a promising solution to create smaller, faster models while maintaining performance.
- This paper investigates the distillation of visual representations in large teacher models into lightweight student models using a small- or mid-scale dataset.
- The study focuses on open-vocabulary out-of-distribution (OOD) generalization, which has been overlooked in previous work.
- The authors propose two principles to enhance student's OOD generalization: better imitating the teacher's visual representation space and enriching the teacher's language representations with semantic attributes.
- Several metrics and experiments are conducted to investigate the proposed approaches.
- The results show significant improvements in student performance on open-vocabulary OOD classification.
- The findings demonstrate the effectiveness of the proposed approaches in enhancing student's OOD generalization ability.
- The study provides valuable insights for distilling large vision-language models and improving OOD generalization. 

Keywords:
- Vision-language models
- Model distillation
- Out-of-distribution generalization
- Visual representations
- Open-vocabulary
- Teacher-student alignment
- Language enrichment
- OOD classification
- Performance improvement
- Experimental analysis