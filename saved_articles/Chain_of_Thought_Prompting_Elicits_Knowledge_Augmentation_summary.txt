Summary:
The paper proposes a method called CoT-KA that uses the chain-of-thought (CoT) prompting technique to retrieve knowledge from large language models (LLMs) and augment it for deep learning. CoT-KA eliminates the need for additional knowledge retrieval or reasoning models. The results show that CoT-KA outperforms other methods on various reasoning tasks across multiple benchmarks.

Bullet Points:
1. CoT-KA is a knowledge augmentation method that uses the chain-of-thought (CoT) prompting technique.
2. CoT-KA leverages large language models (LLMs) as a source of external knowledge.
3. CoT-KA eliminates the need for additional knowledge retrieval or reasoning models.
4. CoT-KA outperforms conventional augmentation methods and pure CoT-based methods on multiple benchmarks.
5. The effectiveness of CoT-KA depends on the number of CoTs generated.
6. CoT-KA achieves better performance on NLU tasks compared to NLG tasks.
7. CoT-KA shows different levels of robustness on different models, with better performance on ALBERT.
8. CoT-KA improves performance compared to a knowledge augmentation method based on entity information.
9. CoT-KA can be further enhanced by developing a CoT selection strategy.
10. Future research could explore other methods to leverage the capabilities of LLMs for knowledge augmentation.

Keywords: knowledge augmentation, chain-of-thought prompting, large language models, reasoning tasks, benchmark