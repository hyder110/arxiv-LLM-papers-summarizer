Large Language Model Displays Emergent Ability to Interpret Novel Literary Metaphors   Nicholas Ichiena,1        Dušan Stamenkovićb.           Keith J. Holyoaka  aDepartment of Psychology, University of California, Los Angeles, CA 90095-1563 bSchool of Culture and Education, Södertörn University, Huddinge, Sweden   SOCIAL SCIENCES: Psychological and Cognitive Sciences   1Corresponding author  Nicholas Ichien Department of Psychology University of California, Los Angeles 405 Hilgard Ave. Los Angeles, CA 90095-1563 ichien@g.ucla.edu  Dušan Stamenković School of Culture and Education Södertörn University Huddinge, Sweden dusan.stamenkovic@sh.se  Keith J. Holyoak Department of Psychology University of California, Los Angeles 405 Hilgard Ave. Los Angeles, CA 90095-1563 kholyoak@g.ucla.edu   Metaphor in GPT-4 
  2 Abstract: Recent advances in the performance of large language models (LLMs) have sparked debate over whether, given sufficient training, high-level human abilities emerge in such generic forms of artificial intelligence (AI). Despite the exceptional performance of LLMs on a wide range of tasks involving natural language processing and reasoning, there has been sharp disagreement as to whether their abilities extend to more creative human abilities. A core example is the ability to interpret novel metaphors. Given the enormous and non-curated text corpora used to train LLMs, a serious obstacle to designing tests is the requirement of finding novel yet high-quality metaphors that are unlikely to have been included in the training data. Here we assessed the ability of GPT-4, a state-of-the-art large language model, to provide natural-language interpretations of novel literary metaphors drawn from Serbian poetry and translated into English. Despite exhibiting no signs of having been exposed to these metaphors previously, the AI system consistently produced detailed and incisive interpretations. Human judges—blind to the fact that an AI model was involved—rated metaphor interpretations generated by GPT-4 as superior to those provided by a group of college students. In interpreting reversed metaphors, GPT-4, as well as humans, exhibited signs of sensitivity to the Gricean cooperative principle. These results indicate that LLMs such as GPT-4 have acquired an emergent ability to interpret complex novel metaphors.  Keywords: metaphor, large language models, natural language processing, text generation   Metaphor in GPT-4 
  3 Significance: One of the most challenging goals for artificial intelligence is to achieve human-like ability to interpret creative uses of language. Despite the many recent successes of current large language models (LLMs) on language tasks, it is unclear whether or not they can deal with novel and creative metaphors. We assessed the performance of GPT-4, a state-of-the-art LLM, in generating natural-language interpretations of unfamiliar metaphors drawn from Serbian poetry and translated into English. Our findings support the conclusion that GPT-4 has indeed acquired the ability to interpret novel literary metaphors that were not in its training data, generating interpretations rated (by judges who were blind to their origin) as superior to those produced by a group of college students.   Metaphor in GPT-4 
  4 \body The poet Robert Frost asserted, “The richest accumulation of the ages is the noble metaphors we have rolled up” (1). The world’s literature (2–4), as well as everyday speech (5), is replete with non-literal comparisons of things that are on the face of it unlike, e.g., “‘Hope’ is the thing with feathers —That perches in the soul” (Emily Dickinson). The ability to create and interpret novel metaphors is considered one of the pinnacles of human cognitive abilities, extending literal language and perhaps involving sophisticated analogical reasoning (6, 7). If artificial intelligence (AI) aims to ultimately reach or exceed human cognitive abilities, then models of natural language processing and general intelligence will need to acquire the ability to interpret (and perhaps create) novel metaphors. The advent of large language models (LLMs) has triggered intense interest in whether these new AI models are in fact approaching human-level abilities in language understanding (8, 9) and various forms of reasoning (10–14), including analogy (15), with vigorous debate between critics (16) and advocates (17). Given the enormous and non-curated text corpora on which LLMs have been trained, these models have certainly had ample opportunity to mine the metaphors that humans have already formed and planted in texts. More generally, recent reports suggest that LLMs have been exposed to some or all standard AI benchmarks for cognitive tasks, rendering these benchmarks suspect for distinguishing deeper cognitive processing from memorization (18). It would not be surprising to find that LLMs succeed on tasks involving linguistic expressions contained in their training data, including metaphors. A serious test of a model’s ability to deal with novel metaphors requires challenging it with metaphors that are both novel and apt (i.e., metaphors in which the source is perceived as providing a unique and accurate description of the target). Unfortunately, detailed information about the training data for LLMs is at present Metaphor in GPT-4 
  5 unavailable, making it difficult to determine definitively whether any given metaphor is truly novel for the system. All conventional metaphors, e.g., “Life is a journey,” are certain to have been included in the text corpora used as the training set. Creating novel metaphors that have never been uploaded to the internet is extremely challenging. Moreover, there is evidence that new metaphors created by psychologists for experimental purposes are typically weak in aptness (19). In general, those metaphors that become conventional are those people have considered to be particularly apt. Here we test GPT-4, a state-of-the-art LLM, on its ability to generate natural-language interpretations of literary metaphors that passed tests assessing their novelty to the model. Computational analyses have shown that literary metaphors are distinguished by the qualities of high surprisal (a statistical measure of the unexpectedness of words), relative dissimilarity of source and target concepts, the combination of concrete words with relatively complex grammar and high lexical diversity, and extra difficulty (for people) in comprehending the metaphorical meaning (20–22). Studies of individual differences in cognitive abilities have shown that crystalized intelligence (closely linked to verbal ability) impacts comprehension of both conventional and literary metaphors; fluid intelligence (on which analogical reasoning depends heavily) plays a greater role for more complex literary metaphors (especially when presented in isolation without a supportive verbal context) (23–25). Novel literary metaphors thus pose the most challenging test of the ability of people—and AI models—to interpret metaphors.  To minimize the possibility that GPT-4 had been trained on our test metaphors and could produce interpretations based on memory for these specific examples, we selected metaphors that originated in Serbian poetry and had been translated into English. The original metaphors were rated as highly apt by native Serbian speakers, but were not widely known to them; the English translations are even less familiar. Details of how the metaphors were selected, and the criteria Metaphor in GPT-4 
  6 used to assess their novelty to GPT-4, are presented in Methods. Both GPT-4 and a group of college students were asked to provide interpretations of these metaphors; their interpretations were then scored for quality by judges who were blind to the fact that an AI system was included in the study. In addition, to calibrate the performance of GPT-4 relative to earlier LLMs, we also tested it on a standard benchmark used in previous assessments. Results   Recent work has evaluated a number of LLMs (GPT-2, GPT-neo, GPT-3, BERT, and RoBERTa) in their ability to generate interpretations of metaphors (26). In a forced-choice paradigm, models and humans were given a metaphor (e.g., “The clothing has the smell of a crowded gym”) and selected one of two literal rephrases of that metaphor (e.g., “The clothing smells pleasant” vs. “The clothing smells awful”). Humans made their selection directly, whereas models did so implicitly by determining which rephrase yielded a higher value on some metric of sentence plausibility (e.g.,  logistic probability for GPT models) when plugged into the following form: “<METAPHOR>, that is to say, <REPHRASE>“ (e.g., “The clothing has the smell of a crowded gym, that is to say, the clothing smells awful”). Across the 1,1146 metaphors in the test set of Liu et al.’s Fig-QA dataset (https://github.com/nightingal3/Fig-QA; leaderboard can be found at: https://explainaboard.inspiredco.ai/leaderboards?dataset=fig_qa), human participants did very well, achieving 94.42% accuracy (95.39% after excluding any problems for which participants reported lack of confidence in their response). Of the models that Liu et al. evaluated, GPT-3 Davinci (27, 28), the largest model (175B parameters, trained on 45TB of text) achieved the best zero-shot performance (68.41%) but still fell well-short of human-level responding. RoBERTa Metaphor in GPT-4 
  7 came close to human-level responding (90.32%), but only after it was fine-tuned on 8,016 similar metaphors. We tested GPT-4 zero-shot by directly prompting the model with natural language text using the following prompt form: “Which of the following is a better interpretation of the following expression: <METAPHOR>. A: <REPHRASE 1> Or B: <REPHRASE 2>?”. The model provided an unambiguous response (e.g., “B. The clothing smells awful”) most of the time, but on 3.35% of questions, it responded with some variant of “Neither A nor B is a direct interpretation of <METAPHOR>.” Counting the latter responses as incorrect, along with those for which the model responded with the wrong interpretation, GPT-4 outperformed both GPT-3 Davinci zero-shot and the fine-tuned RoBERTa, achieving close to human-level performance (91.27%). Thus GPT-4 far outperformed other LLMs in zero-shot performance, and even bested a fine-tuned variant of RoBERTa. GPT-4 is considerably larger than GPT-3 Davinci, the largest model Liu et al. tested (1.8 trillion parameters, trained on 1 PB of text and images). GPT-4 was trained not only on text, but also computer code and images. It also incorporated reinforcement learning with human feedback (RLHF), which served to further align its text output with that generated by humans and rated by them as highly appropriate. The metaphors used in the Fig-QA dataset were all crowdsourced from MTurk workers and the dataset was not published until June 23, 2022—later than September 2021, the latest date that the data used to train GPT-4 were collected (29). It is therefore unlikely that model performance solely reflects GPT-4’s ability to reproduce its memorized training data. However, metaphors generated by MTurk workers are unlikely to be entirely original. Those included in the Fig-QA dataset were clearly easy for humans to reliably interpret, as they achieved nearly ceiling performance. Metaphor in GPT-4 
  8 Table 1. Example of GPT-4’s interpretations of metaphors presented in their canonical direction (left columns) and in their reversed direction (right columns).  Canonical Reversed Metaphor GPT-4 interpretation Metaphor GPT-4 interpretation A waterfall is a wild, unbridled horse. A waterfall symbolizes the untamed, powerful energy of nature, much like the spirit of a wild, unbridled horse. A wild, unbridled horse is a waterfall. A wild, unbridled horse is a waterfall suggests that unrestrained energy and freedom can possess a raw, captivating beauty. A cemetery is a sad theatre. A cemetery is a melancholic stage where the final acts of life are commemorated, and loved ones gather to mourn and remember the departed. A sad theatre is a cemetery. A sad theatre is a cemetery conveys that a place once filled with emotion and expression can become desolate and lifeless when devoid of its original purpose. Love is radiance. Love is the glowing warmth that illuminates and uplifts our lives. Radiance is love. Radiance is love suggests that the emotion of love has the power to illuminate and transform our lives, shining with warmth and positivity.  A stronger test of metaphor ability, for both people and LLMs, is to use novel metaphors created by successful (human) poets. We therefore compared GPT-4 with human reasoners in their ability to produce interpretations of literary metaphors that had been translated into English from Serbian poetry. Metaphors generally had the syntactic form “X is Y” (e.g., “Love is radiance”). In addition to testing the set of original metaphors, we also tested versions in which source and target were reversed, simply swapping their positions (e.g., “Radiance is love”; see Table 1 for additional examples). In general, people find it more difficult to find a sensible interpretation of reversed metaphors(30). GPT-4 and a sample of 39 human participants provided short interpretations of each metaphor in its canonical and reversed form. Any individual participant provided an interpretation for each metaphor in either its canonical or reversed form, but not both. Three human judges blind to the motivation behind this study (in particular, unaware that one participant was an AI system) each scored text responses on a 0-2 scale. (Details can be found in Methods, scoring Metaphor in GPT-4 
  9 criteria can be found in Supplemental Online Information, and rater-generated examples can be found on this paper’s OSF page:  https://osf.io/jcg3f/?view_only=eed36a8a1b9e410aaef1926d020300f9).) We used the clmm function from version 2022.11.16 of the ordinal R package (31) in R version 4.3.1 (32) to fit a cumulative link mixed model to trial-level interpretation scores (0, 1, 2 treated as an ordinal variable). We defined a full model including participant, judge, and metaphor as random intercept effects, and with an interpretation source (GPT-4 vs. human) x metaphor form (canonical vs. reversed) interaction term as fixed effects. Figure 1 shows metaphor score data, broken down according to metaphor form, with GPT-4 coded as one participant. 
 Figure 1. Metaphor interpretation scores (averaged across judges) broken down by metaphor form (canonical vs. reversed). Human data are represented as a boxplot and GPT-4 performance is represented by red points.  We used a likelihood-ratio test to compare this full model to a reduced model that omitted the interpretation source x metaphor form interaction term but that was otherwise equivalent to the full model. Removing the interaction term did not increase model prediction error, ∆AIC = 2,  
Metaphor in GPT-4 
  10 χ2 (1) = .01, p = .92. Inspecting the fit model that omitted the interaction term, we found main effects for both interpretation source (b = .194, z = 2.01, p = .045) and metaphor form (b = .383, z = 7.50, p < .001). As is evident from Figure 1, GPT-4 outscored all human participants, and AI system and humans were both affected by the metaphor form, such that interpretations of metaphors in the reversed form received lower scores than those in the canonical form. 
 Figure 2. Metaphor switching rates (proportion of times an interpretation described the source of a metaphor, rather than its target) broken down by metaphor form (canonical vs. reversed). Human data are represented as a boxplot and GPT-4 performance is represented by red points.  When the metaphors were presented in the reversed (non-canonical) order of source and target (e.g., canonical: “A man is a butterfly” vs. reversed: “A butterfly is a man”), human participants often gave interpretations that restored the canonical order (50% of responses; “A man goes through many phases of growth in order to reach his full potential.”). More generally, we coded the rate at which roles were switched for both canonical and reversed metaphors. As shown in Figure 2, switching was very rare (as would be expected) when the metaphor was presented in canonical form, but was very common when the metaphor was reversed (in which case switching 
Metaphor in GPT-4 
  11 restored the canonical interpretation). Restoring the canonical meaning of a reversed metaphor is consistent with previous findings concerning how people interpret reversed metaphors (30). This propensity likely reflects the Gricean cooperative principle, according to which people seek effective communication (33). Remarkably, GPT-4 gave interpretations of reversed metaphors that restored their canonical meaning at about the same rate (56%) as did humans (50%). Even more striking, the AI system tended to restore the canonical meaning for the same specific metaphors as did people (point-biserial correlation = 0.79, p < .001, across the 55 individual reversed metaphors). These findings suggest that in interpreting metaphors, GPT-4 resembles humans in its sensitivity to pragmatic constraints on communication. Discussion   The language abilities of a state-of-the-art large language model, GPT-4, extend to the interpretation of metaphors, the most prominent form of figurative language. On a standardized AI benchmark test of metaphor interpretation (26), GPT-4—operating in zero-shot fashion without any fine-tuning or in-context learning—greatly outperformed AI models tested previously, and approached the near-ceiling level of human performance. We also compared GPT-4 with humans using a much more challenging set of novel literary metaphors, generated by Serbian poets and translated into English. GPT-4 produced metaphor interpretations that human judges, blind to the fact that an AI system was involved in the study, rated as superior to those written by any of the human participants—college students at a major public university in the United States. GPT-4 also exhibited a human-like propensity to “make sense” of metaphors presented in a non-canonical form (with source and target reversed). On about half the trials, both people and GPT-4 provided interpretations of reversed metaphors that restored their canonical meaning. Moreover, the AI system resembled humans at the level of individual reversed metaphors, reliably reflecting the Metaphor in GPT-4 
  12 probability that a human would restore the canonical meaning at the item level. Our findings add to recent evidence that large language models have begun to acquire some aspects of human pragmatic skills (34).   Although this study has established that GPT-4 can generate very sensible and human-like interpretations of novel literary metaphors, it leaves open the more fundamental question—how does it do it? Achieving scientific understanding of the operation of LLMs such as GPT-4 continues to be impeded by the refusal of their corporate owners to provide either a detailed account of their training data or access to the internal representations the systems have acquired. In the absence of this basic information, we can only speculate. Theories of human metaphor comprehension have fallen into two broad camps (7). One proposal is that metaphors are understood by a process of conceptual combination, in which a semantic vector representing the target is systematically modified to increase its similarity to a semantic vector representing the source (35). Considered as a form of conceptual combination, metaphor comprehension is an extension of the same processes used to process literal language. This view has a clear affinity with the transformer algorithm underlying most LLMs, in which successive layers of a neural network transform embeddings for individual words based on differential attention to the embeddings of other words in the context (36).   An alternative proposal, which traces back to Aristotle and has been advanced by modern cognitive scientists, is that metaphors are comprehended using some form of analogical reasoning (37, 38). Given recent evidence that GPT-3 and GPT-4 are capable of reasoning by analogy across a wide range of problems (15), it is certainly possible that analogy plays a role in GPT-4’s ability to interpret metaphors; indeed, GPT-4 might somehow be integrating conceptual combination with Metaphor in GPT-4 
  13 analogy. Yet we also cannot exclude the possibility that LLMs interpret metaphors using processes fundamentally different from those available to humans.   The ability to interpret novel literary metaphors is a remarkable achievement for AI systems. However, it would be a mistake to conclude that these systems are at present capable of the full range of literary creativity. Although it is widely claimed that LLMs can “write poetry”, their products have yet to be seriously assessed by literary critics. The ability to compose sentences divided into lines linked by end rhymes does not ensure that the product will be “poetry”, defined by a notable critic as “figurative language, concentrated so that its form is both expressive and evocative” (39). Generative AI models can learn to imitate the style of individual creators, but their poetic products so far appear to range from parody to derivative mediocrity.   Specifically with respect to metaphor, the ability to generate interpretations of novel metaphors must not be confused with the ability to generate novel metaphors. Besides being able to generate interpretations of metaphors, as shown here, LLMs can certainly generate texts in which metaphors appear. However, to the best of our current knowledge, the metaphors an LLM might generate are limited to those that human writers have already formed and planted into texts, thereby making humanity’s store of metaphors available to be mined by LLMs (3). It remains to be seen whether AI systems will at some point be able to create genuinely novel metaphors, rather than only variations of those we humans have made already. The great writer Jorge Luis Borges thought that truly new metaphors still await discovery, at least by humans. New variations of old metaphors can be very beautiful, he acknowledged, “and only a few critics like myself would take the trouble to say, ‘Well, there you have eyes and stars and there you have time and the river over and over again.’ The metaphors will strike the imagination. But it may also be given to us—and Metaphor in GPT-4 
  14 why not hope for this as well?—it may also be given to us to invent metaphors that do not belong, or that do not yet belong, to accepted patterns” (40).  Methods Selection of Metaphors The test set included 55 literary metaphors drawn from Serbian poetry and normed on several properties(41, 42). The norming studies (primarily following methods used previously (43)) included metaphors chosen by a literary expert from over 65 nineteenth and twentieth-century poems written by various Serbian poets, such as Branko Radičević, Laza Kostić, Vojislav Ilić, Đura Jakšić, Desanka Maksimović, and Branko Miljković. The poems selected for the norming study aimed to represent a wide range of poetic movements and styles across these two centuries. The expert had the task of extracting all metaphorical expressions from these poems. These were then grouped, with all similar/duplicate metaphors counted as one. Subsequently, all metaphors were transformed into <nominal> is <nominal> format, resulting in the finalized list of 55 items. In the the first norming study, 235 Serbian-speaking participants rated these 55 metaphors for quality, metaphoricity, aptness, familiarity, comprehensibility, and source-target similarity using a 7-point Likert scale (min = 1, max = 7). The inter-scale correlations for Serbian poetic metaphors were reliable for most dimensions (41) (ranging from .77 between aptness and quality, and between quality and source-target similarity, to .27 between familiarity and metaphoricity). The only nonsignificant correlation was that between source-target similarity and metaphoricity (.17). These 55 literary metaphors were then translated into English by two translators and the translations were verified by a third. This new list was subjected to two further norming studies Metaphor in GPT-4 
  15 (42) in which a combined total of 252 (186 for the full set and 66 for a shorter set) English-speaking Serbian participants rated the set for quality, metaphoricity, aptness, and familiarity (see Supplemental Online Information). Human Experiment and Comparison with GPT-4 In order to evaluate GPT-4’s ability to generate high-quality interpretations of metaphors, we compared its interpretations with that of 39 undergraduate psychology students at the University of California, Los Angeles (UCLA), who completed our task for course credit (approved, including informed consent procedures, by the UCLA Office of the Human Research Protection Program). In order to elicit responses from human participants and GPT-4, we plugged each metaphor into the following prompt: “Please provide an expression for the following expression: <SENTENCE>“, where the sentence stated the metaphor. Because GPT-4 tended to provide longer interpretations, we prompted it to provide a “short sentence-long interpretation” to elicit responses that were relatively succinct and of similar length to those generated by human participants. Importantly, the experimental task for both human participants and for GPT-4 omitted any mention of the term ‘metaphor’, opting instead for the more neutral term ‘expression’ as used above. Thus, no overt cue indicated that the task had anything to do with metaphor. Human participants provided interpretations for 55 metaphor items, each in either its canonical form (e.g., “Love is radiance”) or reversed form with source and target switched (e.g., “Radiance is love”). Which form a metaphor took was randomized across items for each participant. Across all unique items (110 total with 55 canonical form and 55 reversed), we collected an average of 19.54 human responses for each item (range = [12, 27]). GPT-4 provided an interpretation of all 110 metaphor items. We collected each response after starting a new chat Metaphor in GPT-4 
  16 window. This procedure prevented the system from conditioning its response on previously-seen metaphor items, so that its performance was zero-shot. After eliciting interpretations from both humans and GPT-4, three undergraduate raters who were naïve to presence of nonhuman, model-generated text scored each interpretation on a 0-2 point scale. Directions for their scoring are provided in Supplemental Online Information and rater-generated examples are available on this paper’s OSF page: https://osf.io/jcg3f/?view_only=eed36a8a1b9e410aaef1926d020300f9. Briefly, raters were instructed to assign interpretations a score of 2 if they attributed properties of the source to the target that described the target aptly. Interpretations were to receive a 1 if they attributed certain properties to the target that seemed less appropriate, especially given the source. Finally, interpretations received a 0 if they were blank or failed to express any sort of comparison.  For each metaphor, raters were given a set of interpretations that had been shuffled so as to mask any common author of interpretations across items. Assessment of Novelty to GPT-4 To evaluate whether GPT-4 was familiar with the metaphors used in our tests, we probed it with questions to assess its knowledge of one paper (41) and an online supplement to another paper (25), in which some of these metaphors were discussed. Neither of these publications included the metaphor interpretations that GPT-4 generated in our tests. GPT-4 recognized one paper (41) and summarized its main points, but was unable to report any of the metaphors in it. When asked for examples, it provided several unrelated metaphorical expressions that did not appear in the study (“hallucinations”). The later paper (25) was published in March 2023, making it too recent to have been included in GPT-4’s training data; the model did not recognize Metaphor in GPT-4 
  17 its online supplement at all. We thus found no evidence that GPT-4 had been exposed to the metaphors used in our test or to the interpretations that the system generated.   Acknowledgements Preparation of this paper was supported by a Google Faculty Research Award to K.J.H. Author Contributions Conceptualization, K.J.H.; Methodology, D.S., K.J.H., N.I.; Formal Analysis, N.I.; Investigation, D.S., N.I.; Writing – Original Draft, D.S., K.J.H., N.I.; Writing – Review & Editing, D.S., K.J.H., N.I.; Supervision, K.J.H.; Funding Acquisition, K.J.H.  Declaration of Interests The authors declare no competing interests.   Metaphor in GPT-4 
  18 