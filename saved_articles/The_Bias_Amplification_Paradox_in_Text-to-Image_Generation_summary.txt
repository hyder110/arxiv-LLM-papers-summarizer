Summary:
This paper investigates bias amplification in text-to-image generation models. The authors compare gender ratios in training and generated images to understand the impact on bias amplification. They find that the model amplifies gender-occupation biases, but this amplification can be largely attributed to discrepancies between training captions and model prompts. Accounting for these differences reduces the amplification considerably. The study highlights the challenges of comparing biases in models and the data they are trained on and emphasizes the confounding factors that contribute to bias amplification.

Bullet Points:
1. The paper explores bias amplification in text-to-image generation models.
2. The authors compare gender ratios in training and generated images to understand bias amplification.
3. The model amplifies gender-occupation biases found in the training data.
4. The amplification can be largely attributed to differences between training captions and model prompts.
5. Discrepancies in gender information in captions and prompts lead to distribution shifts and impact bias measures.
6. Accounting for distributional differences reduces the amplification considerably.
7. The study highlights the challenges of comparing biases in models and training data.
8. Careful consideration of confounding factors is necessary when evaluating bias amplification.
9. The authors propose approaches to reduce distribution shifts and bring data and model bias closer together.
10. The findings have implications for understanding bias amplification and evaluating model behavior.

Keywords:
bias amplification, text-to-image generation, gender-occupation biases, training data, model behavior, distributional differences, confounding factors.